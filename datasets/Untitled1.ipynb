{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144873c3-38ce-4284-9e3f-a6e3b1ffe2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: macOS-13.2.1-arm64-arm-64bit\n",
      "Tensor Flow Version: 2.11.0\n",
      "Keras Version: 2.11.0\n",
      "\n",
      "Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]\n",
      "Pandas 1.5.2\n",
      "Scikit-Learn 1.2.1\n",
      "SciPy 1.10.0\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# import tensorflow.keras\n",
    "# import pandas as pd\n",
    "# import sklearn as sk\n",
    "# import scipy as sp\n",
    "# import tensorflow as tf\n",
    "# import platform\n",
    "# print(f\"Python Platform: {platform.platform()}\")\n",
    "# print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "# print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "# print()\n",
    "# print(f\"Python {sys.version}\")\n",
    "# print(f\"Pandas {pd.__version__}\")\n",
    "# print(f\"Scikit-Learn {sk.__version__}\")\n",
    "# print(f\"SciPy {sp.__version__}\")\n",
    "# gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "# print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3090ba2b-0229-44e4-b0a1-9e67bc09b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "    98304/169001437 [..............................] - ETA: 5:29:29"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cifar \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mcifar100\n\u001b[0;32m----> 4\u001b[0m (x_train, y_train), (x_test, y_test) \u001b[39m=\u001b[39m cifar\u001b[39m.\u001b[39;49mload_data()\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mapplications\u001b[39m.\u001b[39mResNet50(\n\u001b[1;32m      6\u001b[0m     include_top\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m     weights\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m      8\u001b[0m     input_shape\u001b[39m=\u001b[39m(\u001b[39m32\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m),\n\u001b[1;32m      9\u001b[0m     classes\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,)\n\u001b[1;32m     11\u001b[0m loss_fn \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/datasets/cifar100.py:78\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(label_mode)\u001b[0m\n\u001b[1;32m     76\u001b[0m dirname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcifar-100-python\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m origin \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mhttps://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 78\u001b[0m path \u001b[39m=\u001b[39m get_file(\n\u001b[1;32m     79\u001b[0m     dirname,\n\u001b[1;32m     80\u001b[0m     origin\u001b[39m=\u001b[39;49morigin,\n\u001b[1;32m     81\u001b[0m     untar\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     82\u001b[0m     file_hash\u001b[39m=\u001b[39;49m(  \u001b[39m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m     83\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39m85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     84\u001b[0m     ),\n\u001b[1;32m     85\u001b[0m )\n\u001b[1;32m     87\u001b[0m fpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m x_train, y_train \u001b[39m=\u001b[39m load_batch(fpath, label_key\u001b[39m=\u001b[39mlabel_mode \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_labels\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/data_utils.py:300\u001b[0m, in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 300\u001b[0m         urlretrieve(origin, fpath, DLProgbar())\n\u001b[1;32m    301\u001b[0m     \u001b[39mexcept\u001b[39;00m urllib\u001b[39m.\u001b[39merror\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    302\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(error_msg\u001b[39m.\u001b[39mformat(origin, e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmsg))\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/data_utils.py:86\u001b[0m, in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m     84\u001b[0m response \u001b[39m=\u001b[39m urlopen(url, data)\n\u001b[1;32m     85\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m fd:\n\u001b[0;32m---> 86\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m chunk_read(response, reporthook\u001b[39m=\u001b[39mreporthook):\n\u001b[1;32m     87\u001b[0m         fd\u001b[39m.\u001b[39mwrite(chunk)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/keras/utils/data_utils.py:75\u001b[0m, in \u001b[0;36murlretrieve.<locals>.chunk_read\u001b[0;34m(response, chunk_size, reporthook)\u001b[0m\n\u001b[1;32m     73\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     74\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m---> 75\u001b[0m     chunk \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mread(chunk_size)\n\u001b[1;32m     76\u001b[0m     count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m reporthook \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/http/client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m amt \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength:\n\u001b[1;32m    463\u001b[0m     \u001b[39m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m     amt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength\n\u001b[0;32m--> 465\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mread(amt)\n\u001b[1;32m    466\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s \u001b[39mand\u001b[39;00m amt:\n\u001b[1;32m    467\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f4770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "76b33edc9c742098faddc4adcb4b4cdd9ffa47ff0a09cb40c4149dd4293509dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
